{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitTags(tag_list):\n",
    "    tag_list = tag_list.split('|')\n",
    "    output = ''\n",
    "    for tag in tag_list:\n",
    "        output += tag\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get rid of the punctuations and set all characters to lowercase\n",
    "RE_PREPROCESS = r'\\W+|\\d+' #the regular expressions that matches all non-characters\n",
    "\n",
    "#get rid of punctuation and make everything lowercase\n",
    "#the code belows works by looping through the array of text\n",
    "#for a given piece of text we invoke the `re.sub` command where we pass in the regular expression, a space ' ' to\n",
    "#subsitute all the matching characters with\n",
    "#we then invoke the `lower()` method on the output of the re.sub command\n",
    "#to make all the remaining characters\n",
    "#the cleaned document is then stored in a list\n",
    "#once this list has been filed it is then stored in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processFeatures(desc):\n",
    "    try:\n",
    "        return re.sub(RE_PREPROCESS, ' ', desc)\n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processDataFrame(data_frame, country_code='US'):\n",
    "    data_frame.sort_values(by=['video_id', 'trending_date'], ascending=True, inplace=True)\n",
    "    grouped_videos = data_frame.groupby(['video_id']).last().reset_index()\n",
    "    \n",
    "    #Reading categories from the json file depending on country_code\n",
    "    json_location = './data/' + country_code +'_category_id.json'\n",
    "    with open(json_location) as data_file:\n",
    "        data = json.load(data_file)    \n",
    "    categories = []\n",
    "    for item in data['items']:\n",
    "        category = {}\n",
    "        category['category_id'] = int(item['id'])\n",
    "        category['title'] = item['snippet']['title']\n",
    "        categories.append(category)\n",
    "\n",
    "    categories_df = pd.DataFrame(categories)\n",
    "    # Merging videos data with category data\n",
    "    final_df = grouped_videos.merge(categories_df, on = ['category_id'])\n",
    "    final_df.rename(columns={'title_y': 'category', 'title_x': 'video_name'}, inplace=True)\n",
    "    \n",
    "    # Splitting the tags by pipe (|) character\n",
    "    final_df['tags'] = final_df['tags'].apply(splitTags)\n",
    "    \n",
    "    # Creating a features column that consists all features used for prediction.\n",
    "    final_df['video_features'] = final_df['tags'].astype(str) + final_df['video_name'].astype(str) \\\n",
    "                        + final_df['channel_title'].astype(str) + final_df['description'] + final_df['category']\n",
    "        \n",
    "    final_df['video_features'] = final_df['video_features'].apply(process_features)\n",
    "    final_df['video_features'] = final_df['video_features'].apply(process_features)\n",
    "    return final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
